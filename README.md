# ğŸ§  Academic AI Assistant

**An open-source, locally running AI-powered assistant** to support students and researchers during academic writing. The system offers paraphrasing, summarization, grammar checking, citation formatting, and source recommendation functionalitiesâ€”all powered by local large language models (LLMs) like LLaMA 3 and Mistral.

---

## ğŸš€ Features

- âœï¸ AI-assisted **Paraphrasing & Summarization**
- ğŸ” **Grammar and Spelling Checker** using NLP tools
- ğŸ“š **Citation Generator** supporting APA, MLA, and Chicago formats
- ğŸ§¾ **Academic Source Recommender** from a local database
- ğŸ’» Fully **offline**, runs on local open-source LLMs (GGUF format)
- ğŸ–¥ï¸ Frontend options: **Streamlit** or **React**
- ğŸ“¦ Easily packaged with `PyInstaller`

---

## ğŸ§© Project Architecture

```
academic-ai-agent/
â”‚
â”œâ”€â”€ backend/ # Python (FastAPI)
â”‚ â”œâ”€â”€ main.py # FastAPI app & endpoint router
â”‚ â”‚
â”‚ â”œâ”€â”€ models/ # LLM loading and management
â”‚ â”‚ â””â”€â”€ llama_loader.py
â”‚ â”‚
â”‚ â”œâ”€â”€ agents/ # One file per AI task (agent)
â”‚ â”‚ â”œâ”€â”€ paraphrase_agent.py
â”‚ â”‚ â”œâ”€â”€ summary_agent.py
â”‚ â”‚ â”œâ”€â”€ grammar_agent.py
â”‚ â”‚ â”œâ”€â”€ citation_agent.py
â”‚ â”‚ â””â”€â”€ source_agent.py
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/ # NLP & citation formatting helpers
â”‚ â”‚ â”œâ”€â”€ grammar_tools.py
â”‚ â”‚ â”œâ”€â”€ citation_formatter.py
â”‚ â”‚ â””â”€â”€ text_cleaner.py
â”‚ â”‚
â”‚ â”œâ”€â”€ data/ # Local academic sources DB
â”‚ â”‚ â””â”€â”€ sources.db # SQLite database
| |
â”‚ â””â”€â”€ config.py # Model paths and constants
â”‚
â”œâ”€â”€ frontend/ # React frontend (Vite/Next.js)
â”‚ â”œâ”€â”€ public/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ pages/
â”‚ â”‚ â”‚ â”œâ”€â”€ Home.jsx
â”‚ â”‚ â”‚ â”œâ”€â”€ Paraphrase.jsx
â”‚ â”‚ â”‚ â”œâ”€â”€ GrammarCheck.jsx
â”‚ â”‚ â”‚ â”œâ”€â”€ CitationGen.jsx
| | | â”œâ”€â”€ Summariser.jsx
â”‚ â”‚ â”‚ â””â”€â”€ Sources.jsx
â”‚ â”‚ â”œâ”€â”€ api/ # Axios client to FastAPI
â”‚ â”‚ â””â”€â”€ App.jsx
â”‚ â””â”€â”€ package.json
â”‚
â”œâ”€â”€ models/ # GGUF-format local LLMs
â”‚ â””â”€â”€ llama-3-8b-instruct.gguf
â”‚
â”œâ”€â”€ docs/ # MkDocs documentation
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml (optional)
â””â”€â”€ README.md
```

## ğŸ”§ Technologies Used

| Component       | Technology                        |
| --------------- | --------------------------------- |
| AI Model        | LLaMA 3 8B Instruct (GGUF format) |
| AI Framework    | LangChain / LlamaIndex            |
| Backend         | Python (FastAPI)                  |
| Frontend        | Streamlit or React (Vite/Next.js) |
| Database        | SQLite                            |
| NLP Tools       | spaCy, NLTK, TextBlob             |
| Citation Engine | Pybtex, CSL JSON parser           |
| Packaging       | PyInstaller                       |
| Documentation   | MkDocs                            |

---

## âš™ï¸ Setup & Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/academic-ai-agent.git
cd academic-ai-agent
```

### 2. Install backend dependencies

```bash
cd backend
pip install -r requirements.txt
```

### 3. Download and place a GGUF model

Put your llama-3-8b-instruct.gguf or compatible .gguf model inside the models/ directory.

### 4. Run the FastAPI backend

```bash
uvicorn backend.main:app --reload
```

### 5. Run the frontend (React)

```bash
cd frontend
npm install
npm run dev
```
